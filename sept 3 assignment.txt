import pandas as pd
from datetime import datetime

# Sample sales data
data = {
    "TransactionID": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    "CustomerID": [101, 102, 103, 101, 104, 102, 103, 104, 101, 105],
    "ProductID": [501, 502, 501, 503, 504, 502, 503, 504, 501, 505],
    "Quantity": [2, 1, 4, 3, 1, 2, 5, 1, 2, 1],
    "Price": [150.0, 250.0, 150.0, 300.0, 450.0, 250.0, 300.0, 450.0, 150.0, 550.0],
    "Date": [
        datetime(2024, 9, 1),
        datetime(2024, 9, 1),
        datetime(2024, 9, 2),
        datetime(2024, 9, 2),
        datetime(2024, 9, 3),
        datetime(2024, 9, 3),
        datetime(2024, 9, 4),
        datetime(2024, 9, 4),
        datetime(2024, 9, 5),
        datetime(2024, 9, 5)
    ]
}

# Create a DataFrame
df = pd.DataFrame(data)

# Save the DataFrame to a CSV file
df.to_csv('sales_data.csv', index=False)

print("Sample sales dataset has been created and saved as 'sales_data.csv'.")

# 2. **Verify the Dataset:**
#    - After running the script, ensure that the file `sales_data.csv` has been
#    created in your working directory.
with open('sales_data.csv', 'r') as file:
    print(file.read())

# ### **Part 2: Load and Analyze the Dataset Using PySpark**

# Now that you have the dataset, your task is to load it into PySpark and perform
#  the following analysis tasks.
# **Step 2: Load the Dataset into PySpark**

# 1. **Initialize the SparkSession:**
#    - Create a Spark session named `"Sales Dataset Analysis"`.
import pyspark
from pyspark.sql import SparkSession

SalesDatasetAnalysis = SparkSession.builder.appName("SalesDataAnalysis").getOrCreate()


# 2. **Load the CSV File into a PySpark DataFrame:**
#    - Load the `sales_data.csv` file into a PySpark DataFrame.
#    - Display the first few rows of the DataFrame to verify that the data is
#     loaded correctly.
sales_data_df = SalesDatasetAnalysis.read.csv("sales_data.csv", header=True, inferSchema=True)

sales_data_df.show(5)

#### **Step 3: Explore the Data**

# Explore the data to understand its structure.

# 1. **Print the Schema:**
#    - Display the schema of the DataFrame to understand the data types.
sales_data_df.printSchema()

# 2. **Show the First Few Rows:**
#    - Display the first 5 rows of the DataFrame.
sales_data_df.show(5)


# 3. **Get Summary Statistics:**
#    - Get summary statistics for numeric columns (`Quantity` and `Price`).
sales_data_df.describe(["Quantity", "Price"]).show()

#### **Step 4: Perform Data Transformations and Analysis**

# Perform the following tasks to analyze the data:

# 1. **Calculate the Total Sales Value for Each Transaction:**
#    - Add a new column called `TotalSales`, calculated by multiplying `Quantity`
#     by `Price`.
sales_data_df = sales_data_df.withColumn("TotalSales", sales_data_df["Quantity"] * sales_data_df["Price"])
sales_data_df.show()

# 2. **Group By ProductID and Calculate Total Sales Per Product:**
#    - Group the data by `ProductID` and calculate the total sales for each product.
total_sales_by_product = sales_data_df.groupBy("ProductID").agg({"TotalSales": "sum"})
total_sales_by_product = total_sales_by_product.withColumnRenamed("sum(TotalSales)", "TotalSales")
total_sales_by_product.show()

# 3. **Identify the Top-Selling Product:**
#    - Find the product that generated the highest total sales.
top_selling_product = total_sales_by_product.orderBy("TotalSales", descending=True).first()
print("Top-selling product:", top_selling_product)

# 4. **Calculate the Total Sales by Date:**
#    - Group the data by `Date` and calculate the total sales for each day.
total_sales_by_date = sales_data_df.groupBy("Date").agg({"TotalSales": "sum"})
total_sales_by_date = total_sales_by_date.withColumnRenamed("sum(TotalSales)", "TotalSales")
total_sales_by_date.show()

# 5. **Filter High-Value Transactions:**
#    - Filter the transactions to show only those where the total sales value is
#    greater than â‚¹500.
high_value_transactions = sales_data_df.filter(sales_data_df["TotalSales"] > 500)
print("High Value Transactions: ")
high_value_transactions.show()

### **Additional Challenge (Optional):**
# If you complete the tasks above, try extending your analysis with the following
#  challenges:

# 1. **Identify Repeat Customers:**
#    - Count how many times each customer has made a purchase and display the
#     customers who have made more than one purchase.
repeat_customers = sales_data_df.groupBy("CustomerID").count().filter("count > 1")
repeat_customers = repeat_customers.withColumnRenamed("count", "PurchaseCount")
repeat_customers.show()

# 2. **Calculate the Average Sale Price Per Product:**
#    - Calculate the average price per unit for each product and display the results.
average_sale_price_per_product = sales_data_df.groupBy("ProductID").agg({"Price": "avg"})
average_sale_price_per_product = average_sale_price_per_product.withColumnRenamed("avg(Price)", "AverageSalePrice")
average_sale_price_per_product.show()