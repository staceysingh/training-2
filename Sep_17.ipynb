{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/staceysingh/training-2/blob/main/Sep_17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "1411128e-5ae2-4675-8117-0e4526d5dcfb",
          "showTitle": false,
          "title": ""
        },
        "id": "0dX2M3YnHWJ-"
      },
      "source": [
        "###Delta Lake Concepts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d5eafaeb-dabf-4d9c-b68f-c088d0b81a3f",
          "showTitle": false,
          "title": ""
        },
        "id": "IwT_4SPQHWKP",
        "outputId": "61113aa9-e430-4aa1-e0d4-e9685e351193"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbutils.fs.cp(\"file:/Workspace/Shared/employee.csv\", \"dbfs:/FileStore/streaming/input/employee.csv\")\n",
        "dbutils.fs.cp(\"file:/Workspace/Shared/products.json\", \"dbfs:/FileStore/streaming/input/products.json\")\n",
        "dbutils.fs.cp(\"file:/Workspace/Shared/new_employee.csv\", \"dbfs:/FileStore/streaming/input/new_employee.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "fe769c6e-4932-42b5-88b5-f320d4f2f500",
          "showTitle": false,
          "title": ""
        },
        "id": "iSRWO-nEHWKi"
      },
      "source": [
        "Task 1: Creating Delta Table using Three Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "502e4883-91b9-47e9-9719-38dc7141bbc5",
          "showTitle": false,
          "title": ""
        },
        "id": "JQnJKznTHWKl"
      },
      "outputs": [],
      "source": [
        "csv_file = \"dbfs:/FileStore/streaming/input/employee.csv\"\n",
        "json_file = \"dbfs:/FileStore/streaming/input/products.json\"\n",
        "\n",
        "df_csv = spark.read.format(\"csv\").option(\"header\", \"true\").load(csv_file)\n",
        "df_json = spark.read.json(json_file)\n",
        "\n",
        "# 1. Create Delta Table from DataFrame\n",
        "df_csv.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/employees_df\")\n",
        "\n",
        "# 2. Use SQL to create Delta Table\n",
        "df_csv.createOrReplaceTempView(\"employees_view\")\n",
        "spark.sql(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS employees_sql\n",
        "    USING delta\n",
        "    AS SELECT * FROM employees_view\n",
        "\"\"\")\n",
        "\n",
        "# 3. Convert CSV and JSON to Delta format\n",
        "df_csv.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/employees_csv\")\n",
        "\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"ProductID\", StringType(), True),\n",
        "    StructField(\"ProductName\", StringType(), True),\n",
        "    StructField(\"Category\", StringType(), True),\n",
        "    StructField(\"Price\", IntegerType(), True)\n",
        "])\n",
        "df_json = spark.read.schema(schema).json(json_file)\n",
        "\n",
        "df_json.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/products_json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "837d7f35-37cb-4a1b-b0f6-aa2538f2e81c",
          "showTitle": false,
          "title": ""
        },
        "id": "AYZz33ekHWKo"
      },
      "source": [
        "Task 2: Merge and Upsert (Slowly Changing Dimension - SCD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2efb0862-d165-4955-8a41-4da834e8934e",
          "showTitle": false,
          "title": ""
        },
        "id": "2AP864nTHWKt"
      },
      "outputs": [],
      "source": [
        "new_employee_csv_path =\"dbfs:/FileStore/streaming/input/new_employee.csv\"\n",
        "new_employee_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(new_employee_csv_path)\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "new_employee_df = new_employee_df.withColumn(\"EmployeeID\", col(\"EmployeeID\").cast(\"int\")) \\\n",
        "                                 .withColumn(\"Salary\", col(\"Salary\").cast(\"int\"))\n",
        "from delta.tables import DeltaTable\n",
        "\n",
        "delta_table = DeltaTable.forPath(spark, \"/delta/employees_csv\")\n",
        "\n",
        "delta_table.alias(\"old\").merge(\n",
        "    new_employee_df.alias(\"new\"),\n",
        "    \"old.EmployeeID = new.EmployeeID\"\n",
        ").whenMatchedUpdate(set = {\n",
        "    \"EmployeeName\": \"new.EmployeeName\",\n",
        "    \"Department\": \"new.Department\",\n",
        "    \"JoiningDate\": \"new.JoiningDate\",\n",
        "    \"Salary\": \"new.Salary\"\n",
        "}).whenNotMatchedInsertAll().execute()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "0554053d-ca62-42e8-944e-5fd21b2369bb",
          "showTitle": false,
          "title": ""
        },
        "id": "HXHUWNqvHWKw"
      },
      "source": [
        "Task 3: Internals of Delta Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d2c14b23-2246-4a29-bf4f-72b8d3ad1657",
          "showTitle": false,
          "title": ""
        },
        "id": "qP7xiqwSHWKx",
        "outputId": "4537bfc4-6aa2-4aae-eac9-f00c3b3f924a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------------------+----------------+--------------------+---------+--------------------+----+-----------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
            "|version|          timestamp|          userId|            userName|operation| operationParameters| job|         notebook|           clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
            "+-------+-------------------+----------------+--------------------+---------+--------------------+----+-----------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
            "|      3|2024-09-17 04:08:51|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|          2|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|      2|2024-09-17 04:08:48|2929584751483774|azuser2141_mml.lo...|    MERGE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|          1|WriteSerializable|        false|{numTargetRowsCop...|        NULL|Databricks-Runtim...|\n",
            "|      1|2024-09-17 04:05:25|2929584751483774|azuser2141_mml.lo...|    WRITE|{mode -> Overwrit...|NULL|{418182220691607}|0912-053226-p5usobai|          0|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
            "|      0|2024-09-17 04:02:11|2929584751483774|azuser2141_mml.lo...|    WRITE|{mode -> ErrorIfE...|NULL|{418182220691607}|0912-053226-p5usobai|       NULL|WriteSerializable|         true|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
            "+-------+-------------------+----------------+--------------------+---------+--------------------+----+-----------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
            "\n",
            "+----------+------------+-----------+-----------+------+\n",
            "|EmployeeID|EmployeeName| Department|JoiningDate|Salary|\n",
            "+----------+------------+-----------+-----------+------+\n",
            "|       101|        John|         HR| 2023-01-10| 50000|\n",
            "|       102|       Alice|    Finance| 2023-02-15| 70000|\n",
            "|       103|        Mark|Engineering| 2023-03-20| 85000|\n",
            "|       104|        Emma|      Sales| 2023-04-01| 55000|\n",
            "|       105|        Liam|  Marketing| 2023-05-12| 60000|\n",
            "+----------+------------+-----------+-----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check transaction history\n",
        "spark.sql(\"DESCRIBE HISTORY '/delta/employees_csv'\").show()\n",
        "\n",
        "# Perform time travel\n",
        "df_time_travel = spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(\"/delta/employees_csv\")\n",
        "df_time_travel.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "0ecf0efa-ec61-4922-8782-dee8999bf823",
          "showTitle": false,
          "title": ""
        },
        "id": "SxBd81vCHWKz"
      },
      "source": [
        "Task 4: Optimize Delta Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "eadf1984-72b1-4468-9c6c-f3690d0c427f",
          "showTitle": false,
          "title": ""
        },
        "id": "e0qJJUexHWK1",
        "outputId": "9d177910-7caf-401d-eded-d78e829bf00a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBins:bigint,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,numTableColumns:bigint,numTableColumnsWithStats:bigint,totalTaskExecutionTimeMs:bigint,skippedArchivedFiles:bigint,clusteringMetrics:struct<sizeOfTableInBytesBeforeLazyClustering:bigint,isNewMetadataCreated:boolean,isPOTriggered:boolean,numFilesSkippedWithoutStats:bigint,numFilesClassifiedToIntermediateNodes:bigint,sizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,logicalSizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,numFilesClassifiedToLeafNodes:bigint,sizeOfFilesClassifiedToLeafNodesInBytes:bigint,logicalSizeOfFilesClassifiedToLeafNodesInBytes:bigint,numThreadsForClassifier:int,clusterThresholdStrategy:string,minFileSize:bigint,maxFileSize:bigint,nodeMinNumFilesToCompact:bigint,numIdealFiles:bigint,numClusteringTasksPlanned:int,numCompactionTasksPlanned:int,numOptimizeBatchesPlanned:int,numLeafNodesExpanded:bigint,numLeafNodesClustered:bigint,numGetFilesForNodeCalls:bigint,numSamplingJobs:bigint,numLeafNodesCompacted:bigint,numIntermediateNodesCompacted:bigint,totalSizeOfDataToCompactInBytes:bigint,totalLogicalSizeOfDataToCompactInBytes:bigint,numIntermediateNodesClustered:bigint,numFilesSkippedAfterExpansion:bigint,totalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalLogicalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalSizeOfDataToRewriteInBytes:bigint,totalLogicalSizeOfDataToRewriteInBytes:bigint,timeMetrics:struct<classifierTimeMs:bigint,optimizerTimeMs:bigint,metadataLoadTimeMs:bigint,totalGetFilesForNodeCallsTimeMs:bigint,totalSamplingTimeMs:bigint,metadataCreationTimeMs:bigint>,maxOptimizeBatchesInParallel:bigint,currentIteration:int,maxIterations:int,clusteringStrategy:string>>]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.sql(\"OPTIMIZE '/delta/employees_csv' ZORDER BY Department\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "6256caf4-d3a1-402f-8315-3b2f10b4fea1",
          "showTitle": false,
          "title": ""
        },
        "id": "f46lxcRzHWK6"
      },
      "source": [
        "Task 5: Time Travel with Delta Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d77419d3-1d3c-4c96-a045-c60fba439053",
          "showTitle": false,
          "title": ""
        },
        "id": "R8Y6wYjUHWK9",
        "outputId": "598a15b8-5144-4971-b73b-a4e57f6a2dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------------+-----------+-----------+------+\n",
            "|EmployeeID|EmployeeName| Department|JoiningDate|Salary|\n",
            "+----------+------------+-----------+-----------+------+\n",
            "|       101|        John|         HR| 2023-01-10| 50000|\n",
            "|       102|       Alice|    Finance| 2023-02-15| 70000|\n",
            "|       103|        Mark|Engineering| 2023-03-20| 85000|\n",
            "|       104|        Emma|      Sales| 2023-04-01| 55000|\n",
            "|       105|        Liam|  Marketing| 2023-05-12| 60000|\n",
            "+----------+------------+-----------+-----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_time_travel = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"/delta/employees_csv\")\n",
        "df_time_travel.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "b2a532c6-5229-4f0c-9b93-04e9d997cf77",
          "showTitle": false,
          "title": ""
        },
        "id": "x0gzt1z3HWLA"
      },
      "source": [
        "Task 6: Vacuum Delta Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e6ffb24e-fd64-4110-a4df-c00668f10f8f",
          "showTitle": false,
          "title": ""
        },
        "id": "nrrCLWHbHWLD",
        "outputId": "a57c2511-2c17-42b1-8f05-2c5c956436f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[path: string]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.sql(\"VACUUM '/delta/employees_csv' RETAIN 168 HOURS\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "8610dcf2-56d6-4de8-bb82-bcee2781a464",
          "showTitle": false,
          "title": ""
        },
        "id": "IH_j6LBLHWLF"
      },
      "source": [
        "### Structured Streaming and Transformations on Streams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f82cc6b9-1852-4869-ae7d-9e0f88af1e6c",
          "showTitle": false,
          "title": ""
        },
        "id": "4DT0n4IJHWLG",
        "outputId": "e7f85f83-ef21-4fab-bacd-82dd4afadf16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbutils.fs.cp(\"file:/Workspace/Shared/transactions.csv\", \"dbfs:/FileStore/streaming/input/transactions.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "dad02041-cdd4-437e-b76b-a734561c8e94",
          "showTitle": false,
          "title": ""
        },
        "id": "PdL0CiTmHWLJ"
      },
      "source": [
        "Task 1: Ingest Streaming Data from CSV Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "84b499ad-e864-4f18-acbf-242dd5d01f87",
          "showTitle": false,
          "title": ""
        },
        "id": "IoEmg62pHWLK"
      },
      "outputs": [],
      "source": [
        "static_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/streaming/input/transactions.csv\")\n",
        "schema = static_df.schema\n",
        "\n",
        "streaming_df = spark.readStream.format(\"csv\").option(\"header\", \"true\").schema(schema).load(\"dbfs:/FileStore/streaming/input/\")\n",
        "\n",
        "query = streaming_df.writeStream.format(\"console\").start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "ac06126f-449d-4b28-9121-1b6e5d4a7bbe",
          "showTitle": false,
          "title": ""
        },
        "id": "sr9Wqg5BHWLN"
      },
      "source": [
        "Task 2: Stream Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7de1d881-2085-4ef8-b693-890cd021c7d6",
          "showTitle": false,
          "title": ""
        },
        "id": "7IrK0XoyHWLO"
      },
      "outputs": [],
      "source": [
        "#Add a new column for the TotalAmount ( Quantity * Price ).\n",
        "#Filter records where the Quantity is greater than 1.\n",
        "transformed_df = streaming_df.withColumn(\"TotalAmount\", streaming_df[\"Quantity\"] * streaming_df[\"Price\"]).filter(streaming_df[\"Quantity\"] > 1)\n",
        "\n",
        "query = transformed_df.writeStream.format(\"memory\").queryName(\"transformed_stream\").start()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "4115e790-0651-4a23-854d-1b94b631fda1",
          "showTitle": false,
          "title": ""
        },
        "id": "yX7UinqgHWLQ"
      },
      "source": [
        "Task 3: Aggregations on Streaming Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a390981a-819d-44ab-a994-5dcf73f8bad6",
          "showTitle": false,
          "title": ""
        },
        "id": "qe2Ilw1OHWLR"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, sum\n",
        "#Group the data by ProductID and calculate the total sales for each product\n",
        "aggregated_df = streaming_df.groupBy(\"ProductID\").agg(sum(col(\"Quantity\") * col(\"Price\")).alias(\"TotalSales\"))\n",
        "query = aggregated_df.writeStream.format(\"console\").outputMode(\"update\").start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "44400491-7d18-4198-818f-dff585be6f79",
          "showTitle": false,
          "title": ""
        },
        "id": "r37IqSsKHWLT"
      },
      "source": [
        "Task 4: Writing Streaming Data to File Sinks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "226ecde6-ae6c-4560-bb37-625145e05c23",
          "showTitle": false,
          "title": ""
        },
        "id": "TUuxSdKoHWLT"
      },
      "outputs": [],
      "source": [
        "query = transformed_df.writeStream.format(\"parquet\").option(\"path\", \"/dbfs/FileStore/parquet\") \\\n",
        "                                   .option(\"checkpointLocation\", \"/dbfs/FileStore/checkpoint\") \\\n",
        "                                   .start()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "49cab256-73c3-499d-9fc8-599ac299ff32",
          "showTitle": false,
          "title": ""
        },
        "id": "jrnRsKJXHWLU"
      },
      "source": [
        "Task 5: Handling Late Data using Watermarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "62848a9b-e39d-49a1-95ee-756c0f573aed",
          "showTitle": false,
          "title": ""
        },
        "id": "y4lHk3O-HWLV"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, to_timestamp\n",
        "\n",
        "streaming_df = streaming_df.withColumn(\"TransactionDate\", to_timestamp(col(\"TransactionDate\")))\n",
        "\n",
        "watermarked_df = streaming_df.withWatermark(\"TransactionDate\", \"1 day\")\n",
        "\n",
        "watermarked_query = watermarked_df.writeStream.format(\"console\").start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "68a3d79c-bfca-445b-8083-ce572cb8e9c3",
          "showTitle": false,
          "title": ""
        },
        "id": "GwrdjofvHWLW"
      },
      "source": [
        "Task 6: Streaming from Multiple Sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "fb8a6776-99c6-4d5c-b969-eba2d322f6ba",
          "showTitle": false,
          "title": ""
        },
        "id": "a_djJpPrHWLX"
      },
      "outputs": [],
      "source": [
        "# Stream 1: Incoming transaction data (CSV)\n",
        "transactions_stream = spark.readStream.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"basePath\", \"dbfs:/FileStore/streaming/input/\") \\\n",
        "    .schema(\"TransactionID STRING, TransactionDate DATE, ProductID STRING, Quantity INT, Price DOUBLE\") \\\n",
        "    .load(\"dbfs:/FileStore/streaming/input/\")\n",
        "\n",
        "# Stream 2: Product information (JSON)\n",
        "products_stream = spark.readStream.format(\"json\") \\\n",
        "    .option(\"basePath\", \"dbfs:/FileStore/streaming/input/\") \\\n",
        "    .schema(\"ProductID STRING, ProductName STRING, Category STRING\") \\\n",
        "    .load(\"dbfs:/FileStore/streaming/input/\")\n",
        "\n",
        "# Join both streams on ProductID\n",
        "joined_stream = transactions_stream.join(products_stream, \"ProductID\")\n",
        "\n",
        "# Write the joined stream to the console to visualize results\n",
        "query = joined_stream.writeStream \\\n",
        "    .format(\"console\") \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "2659cd45-c291-4a7a-83a1-3c6afa8d219a",
          "showTitle": false,
          "title": ""
        },
        "id": "Av8I3J-DHWLZ"
      },
      "source": [
        "Task 7: Stopping and Restarting Streaming Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e3669b33-0c2a-48ce-9243-464bade5fabd",
          "showTitle": false,
          "title": ""
        },
        "id": "P7PBG7ZJHWLb"
      },
      "source": [
        "### Creating a Complete ETL Pipeline using Delta Live Tables (DLT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "23600180-8a1c-45f4-b279-b4df33a1be55",
          "showTitle": false,
          "title": ""
        },
        "id": "E4iVV03zHWLc",
        "outputId": "e996e49c-dc46-4e3e-b8b1-2a92794e577f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbutils.fs.cp(\"file:/Workspace/Shared/orders.csv\", \"dbfs:/FileStore/streaming/input/orders.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "1fb014ac-5acd-416e-b35a-466080f751fd",
          "showTitle": false,
          "title": ""
        },
        "id": "6s7kYFl_HWLf"
      },
      "source": [
        "Task 1: Create an ETL Pipeline using DLT (Python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6c53f852-6186-4767-8730-d78eafb16ba8",
          "showTitle": false,
          "title": ""
        },
        "id": "bsoVNudUHWLh",
        "outputId": "4a94062e-cacf-49ac-e318-b4e17c0b77c5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<html>\n",
              "  <style>\n",
              "<style>\n",
              "      html {\n",
              "        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,\n",
              "        Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,\n",
              "        Noto Color Emoji,FontAwesome;\n",
              "        font-size: 13;\n",
              "      }\n",
              "\n",
              "      .ansiout {\n",
              "        padding-bottom: 8px;\n",
              "      }\n",
              "\n",
              "      .createPipeline {\n",
              "        background-color: rgb(34, 114, 180);\n",
              "        color: white;\n",
              "        text-decoration: none;\n",
              "        padding: 4px 12px;\n",
              "        border-radius: 4px;\n",
              "        display: inline-block;\n",
              "      }\n",
              "\n",
              "      .createPipeline:hover {\n",
              "        background-color: #195487;\n",
              "      }\n",
              "\n",
              "      .tag {\n",
              "        border: none;\n",
              "        color: rgb(31, 39, 45);\n",
              "        padding: 2px 4px;\n",
              "        font-weight: 600;\n",
              "        background-color: rgba(93, 114, 131, 0.08);\n",
              "        border-radius: 4px;\n",
              "        margin-right: 0;\n",
              "        display: inline-block;\n",
              "        cursor: default;\n",
              "      }\n",
              "\n",
              "      table {\n",
              "        border-collapse: collapse;\n",
              "        font-size: 13px;\n",
              "      }\n",
              "\n",
              "      th {\n",
              "        text-align: left;\n",
              "        background-color: #F2F5F7;\n",
              "        padding-left: 8px;\n",
              "        padding-right: 8px;\n",
              "      }\n",
              "\n",
              "      tr {\n",
              "        border-bottom: solid;\n",
              "        border-bottom-color: #CDDAE5;\n",
              "        border-bottom-width: 1px;\n",
              "      }\n",
              "\n",
              "      td {\n",
              "        padding-left: 8px;\n",
              "        padding-right: 8px;\n",
              "      }\n",
              "\n",
              "      .dlt-label {\n",
              "        font-weight: bold;\n",
              "      }\n",
              "\n",
              "      ul {\n",
              "        list-style: circle;\n",
              "        padding-inline-start: 12px;\n",
              "      }\n",
              "\n",
              "      li {\n",
              "        padding-bottom: 4px;\n",
              "      }\n",
              "</style></style>\n",
              "  \n",
              "<div class=\"ansiout\">\n",
              "<span class='tag'>incremental_orders</span> is defined as a\n",
              "<span class=\"dlt-label\">Delta Live Tables</span> dataset\n",
              " with schema: \n",
              "</div>\n",
              "\n",
              "  \n",
              "<div class=\"ansiout\">\n",
              "   <table>\n",
              "     <tbody>\n",
              "       <tr>\n",
              "         <th>Name</th>\n",
              "         <th>Type</th>\n",
              "       </tr>\n",
              "       \n",
              "<tr>\n",
              "   <td>OrderID</td>\n",
              "   <td>string</td>\n",
              "</tr>\n",
              "\n",
              "<tr>\n",
              "   <td>OrderDate</td>\n",
              "   <td>string</td>\n",
              "</tr>\n",
              "\n",
              "<tr>\n",
              "   <td>CustomerID</td>\n",
              "   <td>string</td>\n",
              "</tr>\n",
              "\n",
              "<tr>\n",
              "   <td>Product</td>\n",
              "   <td>string</td>\n",
              "</tr>\n",
              "\n",
              "<tr>\n",
              "   <td>Quantity</td>\n",
              "   <td>string</td>\n",
              "</tr>\n",
              "\n",
              "<tr>\n",
              "   <td>Price</td>\n",
              "   <td>string</td>\n",
              "</tr>\n",
              "\n",
              "<tr>\n",
              "   <td>TotalAmount</td>\n",
              "   <td>double</td>\n",
              "</tr>\n",
              "     </tbody>\n",
              "   </table>\n",
              "</div>\n",
              "\n",
              "  <div class =\"ansiout\">\n",
              "    To populate your table you must either:\n",
              "    <ul>\n",
              "      <li>\n",
              "        Run an existing pipeline using the\n",
              "        <span class=\"dlt-label\">Delta Live Tables</span> menu\n",
              "      </li>\n",
              "      <li>\n",
              "        Create a new pipeline: <a class='createPipeline' href=\"?o=419276616380425#joblist/pipelines/create?initialSource=%2FUsers%2Fazuser2141_mml.local%40techademy.com%2FSep%2017&redirectNotebookId=418182220691607\">Create Pipeline</a>\n",
              "      </li>\n",
              "    </ul>\n",
              "  <div>\n",
              "</html>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import dlt\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "@dlt.table\n",
        "def transformed_orders():\n",
        "    # Read CSV source\n",
        "    df = spark.read.csv(\"dbfs:/FileStore/streaming/input/orders.csv\", header=True)\n",
        "\n",
        "    # Transform data\n",
        "    df_transformed = df.withColumn(\"TotalAmount\", col(\"Quantity\") * col(\"Price\")) \\\n",
        "                       .filter(col(\"Quantity\") > 1)\n",
        "\n",
        "    return df_transformed\n",
        "\n",
        "@dlt.table\n",
        "def incremental_orders():\n",
        "    return dlt.read_stream(\"transformed_orders\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "184825cd-a2b4-4524-8008-6543c70208c7",
          "showTitle": false,
          "title": ""
        },
        "id": "u3bush_YHWLj"
      },
      "source": [
        "Task 2: Create an ETL Pipeline using DLT (SQL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c6bea20f-7b6e-42d0-89a8-b1f0c6b7d9cb",
          "showTitle": false,
          "title": ""
        },
        "id": "4pchWNYvHWLk"
      },
      "outputs": [],
      "source": [
        "# Load the CSV file\n",
        "df_orders = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"dbfs:/FileStore/streaming/input/orders.csv\")\n",
        "\n",
        "df_orders.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/orders\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "implicitDf": true,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "77eb71e2-e10e-493c-9cb2-9904102f7c74",
          "showTitle": false,
          "title": ""
        },
        "id": "1k8MIXbtHWLl",
        "outputId": "4206dd51-ef99-4eda-eb3f-52362c66d02c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<html>\n",
              "  <style>\n",
              "<style>\n",
              "      html {\n",
              "        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,\n",
              "        Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,\n",
              "        Noto Color Emoji,FontAwesome;\n",
              "        font-size: 13;\n",
              "      }\n",
              "\n",
              "      .ansiout {\n",
              "        padding-bottom: 8px;\n",
              "      }\n",
              "\n",
              "      .createPipeline {\n",
              "        background-color: rgb(34, 114, 180);\n",
              "        color: white;\n",
              "        text-decoration: none;\n",
              "        padding: 4px 12px;\n",
              "        border-radius: 4px;\n",
              "        display: inline-block;\n",
              "      }\n",
              "\n",
              "      .createPipeline:hover {\n",
              "        background-color: #195487;\n",
              "      }\n",
              "\n",
              "      .tag {\n",
              "        border: none;\n",
              "        color: rgb(31, 39, 45);\n",
              "        padding: 2px 4px;\n",
              "        font-weight: 600;\n",
              "        background-color: rgba(93, 114, 131, 0.08);\n",
              "        border-radius: 4px;\n",
              "        margin-right: 0;\n",
              "        display: inline-block;\n",
              "        cursor: default;\n",
              "      }\n",
              "\n",
              "      table {\n",
              "        border-collapse: collapse;\n",
              "        font-size: 13px;\n",
              "      }\n",
              "\n",
              "      th {\n",
              "        text-align: left;\n",
              "        background-color: #F2F5F7;\n",
              "        padding-left: 8px;\n",
              "        padding-right: 8px;\n",
              "      }\n",
              "\n",
              "      tr {\n",
              "        border-bottom: solid;\n",
              "        border-bottom-color: #CDDAE5;\n",
              "        border-bottom-width: 1px;\n",
              "      }\n",
              "\n",
              "      td {\n",
              "        padding-left: 8px;\n",
              "        padding-right: 8px;\n",
              "      }\n",
              "\n",
              "      .dlt-label {\n",
              "        font-weight: bold;\n",
              "      }\n",
              "\n",
              "      ul {\n",
              "        list-style: circle;\n",
              "        padding-inline-start: 12px;\n",
              "      }\n",
              "\n",
              "      li {\n",
              "        padding-bottom: 4px;\n",
              "      }\n",
              "</style></style>\n",
              "  \n",
              "<div class=\"ansiout\">\n",
              "<span class='tag'>transformed_orders</span> is defined as a\n",
              "<span class=\"dlt-label\">Delta Live Tables</span> dataset\n",
              " with schema: \n",
              "</div>\n",
              "\n",
              "  \n",
              "<div class=\"ansiout\">\n",
              "   <table>\n",
              "     <tbody>\n",
              "       <tr>\n",
              "         <th>Name</th>\n",
              "         <th>Type</th>\n",
              "       </tr>\n",
              "       \n",
              "<tr>\n",
              "   <td>OrderID</td>\n",
              "   <td>int</td>\n",
              "</tr>\n",
              "\n",
              "<tr>\n",
              "   <td>OrderDate</td>\n",
              "   <td>date</td>\n",
              "</tr>\n",
              "\n",
              "<tr>\n",
              "   <td>CustomerID</td>\n",
              "   <td>string</td>\n",
              "</tr>\n",
              "\n",
              "<tr>\n",
              "   <td>Product</td>\n",
              "   <td>string</td>\n",
              "</tr>\n",
              "\n",
              "<tr>\n",
              "   <td>Quantity</td>\n",
              "   <td>int</td>\n",
              "</tr>\n",
              "\n",
              "<tr>\n",
              "   <td>Price</td>\n",
              "   <td>int</td>\n",
              "</tr>\n",
              "\n",
              "<tr>\n",
              "   <td>TotalAmount</td>\n",
              "   <td>int</td>\n",
              "</tr>\n",
              "     </tbody>\n",
              "   </table>\n",
              "</div>\n",
              "\n",
              "  <div class =\"ansiout\">\n",
              "    To populate your table you must either:\n",
              "    <ul>\n",
              "      <li>\n",
              "        Run an existing pipeline using the\n",
              "        <span class=\"dlt-label\">Delta Live Tables</span> menu\n",
              "      </li>\n",
              "      <li>\n",
              "        Create a new pipeline: <a class='createPipeline' href=\"?o=419276616380425#joblist/pipelines/create?initialSource=%2FUsers%2Fazuser2141_mml.local%40techademy.com%2FSep%2017&redirectNotebookId=418182220691607\">Create Pipeline</a>\n",
              "      </li>\n",
              "    </ul>\n",
              "  <div>\n",
              "</html>\n"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "arguments": {},
              "data": "\n<html>\n  <style>\n<style>\n      html {\n        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,\n        Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,\n        Noto Color Emoji,FontAwesome;\n        font-size: 13;\n      }\n\n      .ansiout {\n        padding-bottom: 8px;\n      }\n\n      .createPipeline {\n        background-color: rgb(34, 114, 180);\n        color: white;\n        text-decoration: none;\n        padding: 4px 12px;\n        border-radius: 4px;\n        display: inline-block;\n      }\n\n      .createPipeline:hover {\n        background-color: #195487;\n      }\n\n      .tag {\n        border: none;\n        color: rgb(31, 39, 45);\n        padding: 2px 4px;\n        font-weight: 600;\n        background-color: rgba(93, 114, 131, 0.08);\n        border-radius: 4px;\n        margin-right: 0;\n        display: inline-block;\n        cursor: default;\n      }\n\n      table {\n        border-collapse: collapse;\n        font-size: 13px;\n      }\n\n      th {\n        text-align: left;\n        background-color: #F2F5F7;\n        padding-left: 8px;\n        padding-right: 8px;\n      }\n\n      tr {\n        border-bottom: solid;\n        border-bottom-color: #CDDAE5;\n        border-bottom-width: 1px;\n      }\n\n      td {\n        padding-left: 8px;\n        padding-right: 8px;\n      }\n\n      .dlt-label {\n        font-weight: bold;\n      }\n\n      ul {\n        list-style: circle;\n        padding-inline-start: 12px;\n      }\n\n      li {\n        padding-bottom: 4px;\n      }\n</style></style>\n  \n<div class=\"ansiout\">\n<span class='tag'>transformed_orders</span> is defined as a\n<span class=\"dlt-label\">Delta Live Tables</span> dataset\n with schema: \n</div>\n\n  \n<div class=\"ansiout\">\n   <table>\n     <tbody>\n       <tr>\n         <th>Name</th>\n         <th>Type</th>\n       </tr>\n       \n<tr>\n   <td>OrderID</td>\n   <td>int</td>\n</tr>\n\n<tr>\n   <td>OrderDate</td>\n   <td>date</td>\n</tr>\n\n<tr>\n   <td>CustomerID</td>\n   <td>string</td>\n</tr>\n\n<tr>\n   <td>Product</td>\n   <td>string</td>\n</tr>\n\n<tr>\n   <td>Quantity</td>\n   <td>int</td>\n</tr>\n\n<tr>\n   <td>Price</td>\n   <td>int</td>\n</tr>\n\n<tr>\n   <td>TotalAmount</td>\n   <td>int</td>\n</tr>\n     </tbody>\n   </table>\n</div>\n\n  <div class =\"ansiout\">\n    To populate your table you must either:\n    <ul>\n      <li>\n        Run an existing pipeline using the\n        <span class=\"dlt-label\">Delta Live Tables</span> menu\n      </li>\n      <li>\n        Create a new pipeline: <a class='createPipeline' href=\"?o=419276616380425#joblist/pipelines/create?initialSource=%2FUsers%2Fazuser2141_mml.local%40techademy.com%2FSep%2017&redirectNotebookId=418182220691607\">Create Pipeline</a>\n      </li>\n    </ul>\n  <div>\n</html>\n",
              "datasetInfos": [],
              "metadata": {
                "dataframeName": null
              },
              "removedWidgets": [],
              "textData": null,
              "type": "htmlSandbox"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%sql\n",
        "CREATE OR REPLACE LIVE TABLE transformed_orders AS\n",
        "SELECT *, Quantity * Price AS TotalAmount\n",
        "FROM delta.`/delta/orders`\n",
        "WHERE Quantity > 1;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "6fee46da-b3af-4cb7-90eb-7324fde0e1f2",
          "showTitle": false,
          "title": ""
        },
        "id": "W6BMDy08HWLp"
      },
      "source": [
        "Task 3: Perform Read, Write, Update, and Delete Operations on Delta Table (SQL + PySpark)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e5bdc65f-6b9b-409c-9443-9a4a237152f5",
          "showTitle": false,
          "title": ""
        },
        "id": "L7mKgz5wHWLr"
      },
      "source": [
        "1. Read the Data from the Delta Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "da42e36d-2ae1-49dd-a295-d56c0144594b",
          "showTitle": false,
          "title": ""
        },
        "id": "-Z2j7FdfHWLs",
        "outputId": "f60cd75e-8eae-43e5-ffb1-d8f2a054f992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+----------+-------+--------+-----+\n",
            "|OrderID| OrderDate|CustomerID|Product|Quantity|Price|\n",
            "+-------+----------+----------+-------+--------+-----+\n",
            "|    101|2024-01-01|      C001| Laptop|       2| 1000|\n",
            "|    102|2024-01-02|      C002|  Phone|       1|  500|\n",
            "|    103|2024-01-03|      C003| Tablet|       3|  300|\n",
            "|    104|2024-01-04|      C004|Monitor|       1|  150|\n",
            "|    105|2024-01-05|      C005|  Mouse|       5|   20|\n",
            "+-------+----------+----------+-------+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Reading the Delta table in PySpark\n",
        "df = spark.read.format(\"delta\").load(\"/delta/orders\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "implicitDf": true,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "78ebcbf1-09a1-4f75-856c-27a45b5db1ba",
          "showTitle": false,
          "title": ""
        },
        "id": "xBCgRTyMHWL2",
        "outputId": "e40b2977-5b15-49b6-cc14-dbc2aae0f6f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>OrderID</th><th>OrderDate</th><th>CustomerID</th><th>Product</th><th>Quantity</th><th>Price</th></tr></thead><tbody><tr><td>101</td><td>2024-01-01</td><td>C001</td><td>Laptop</td><td>2</td><td>1000</td></tr><tr><td>102</td><td>2024-01-02</td><td>C002</td><td>Phone</td><td>1</td><td>500</td></tr><tr><td>103</td><td>2024-01-03</td><td>C003</td><td>Tablet</td><td>3</td><td>300</td></tr><tr><td>104</td><td>2024-01-04</td><td>C004</td><td>Monitor</td><td>1</td><td>150</td></tr><tr><td>105</td><td>2024-01-05</td><td>C005</td><td>Mouse</td><td>5</td><td>20</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  101,
                  "2024-01-01",
                  "C001",
                  "Laptop",
                  2,
                  1000
                ],
                [
                  102,
                  "2024-01-02",
                  "C002",
                  "Phone",
                  1,
                  500
                ],
                [
                  103,
                  "2024-01-03",
                  "C003",
                  "Tablet",
                  3,
                  300
                ],
                [
                  104,
                  "2024-01-04",
                  "C004",
                  "Monitor",
                  1,
                  150
                ],
                [
                  105,
                  "2024-01-05",
                  "C005",
                  "Mouse",
                  5,
                  20
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "createTempViewForImplicitDf": true,
                "dataframeName": "_sqldf",
                "executionCount": 71
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "OrderID",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
                  "name": "OrderDate",
                  "type": "\"date\""
                },
                {
                  "metadata": "{}",
                  "name": "CustomerID",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "Product",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "Quantity",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "Price",
                  "type": "\"integer\""
                }
              ],
              "type": "table"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%sql\n",
        "-- Reading the Delta table using SQL\n",
        "SELECT * FROM delta.`/delta/orders`;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "734eb089-92c0-4733-a778-7e5c6d1517cb",
          "showTitle": false,
          "title": ""
        },
        "id": "bFoudCpXHWL4"
      },
      "source": [
        "2. Update the Price of a Product (e.g., increase Laptop price by 10%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2935f4a7-5b13-477b-b1f6-8d47ac90d263",
          "showTitle": false,
          "title": ""
        },
        "id": "1h5bFIIVHWL7"
      },
      "outputs": [],
      "source": [
        "from delta.tables import DeltaTable\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "# Load the Delta table\n",
        "delta_table = DeltaTable.forPath(spark, \"/delta/orders\")\n",
        "\n",
        "# Update the Price of 'Laptop' by increasing it by 10%\n",
        "delta_table.update(\n",
        "    condition = expr(\"Product = 'Laptop'\"),\n",
        "    set = { \"Price\": expr(\"Price * 1.1\") }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "implicitDf": true,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "fc909a0d-ae57-4dc0-8989-63a0c55f3f4b",
          "showTitle": false,
          "title": ""
        },
        "id": "cJbZnniiHWL8",
        "outputId": "5401603c-edca-4b50-e678-c57ad15960a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th></tr></thead><tbody><tr><td>1</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  1
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "createTempViewForImplicitDf": true,
                "dataframeName": "_sqldf",
                "executionCount": 76
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "num_affected_rows",
                  "type": "\"long\""
                }
              ],
              "type": "table"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%sql\n",
        "-- Update product price using SQL (increase Laptop price by 10%)\n",
        "UPDATE delta.`/delta/orders`\n",
        "SET Price = Price * 1.1\n",
        "WHERE Product = 'Laptop';\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "647c0841-72ba-41a8-a002-d94d3d349540",
          "showTitle": false,
          "title": ""
        },
        "id": "RQZwydjyHWMB"
      },
      "source": [
        "3. Delete Rows where Quantity is Less Than 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e06a7136-fd7f-42b0-b1a4-3a1e8c663932",
          "showTitle": false,
          "title": ""
        },
        "id": "O2fykdc3HWMD"
      },
      "outputs": [],
      "source": [
        "# Delete rows where Quantity is less than 2\n",
        "delta_table.delete(condition = expr(\"Quantity < 2\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "implicitDf": true,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0147aed9-e555-4527-b549-f04503c29ee9",
          "showTitle": false,
          "title": ""
        },
        "id": "Tt8PKVifHWMF",
        "outputId": "4fd1fdb8-865d-4130-fbe9-45956c447589"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th></tr></thead><tbody><tr><td>0</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  0
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "createTempViewForImplicitDf": true,
                "dataframeName": "_sqldf",
                "executionCount": 80
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "num_affected_rows",
                  "type": "\"long\""
                }
              ],
              "type": "table"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%sql\n",
        "-- Delete rows where Quantity is less than 2\n",
        "DELETE FROM delta.`/delta/orders`\n",
        "WHERE Quantity < 2;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "9195dd06-f33b-4cea-b8af-8a570dc93a1c",
          "showTitle": false,
          "title": ""
        },
        "id": "rr7nX3-qHWMG"
      },
      "source": [
        "4. Insert a New Record into the Delta Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "459741e8-1fd7-429f-a85d-938ce5dfd996",
          "showTitle": false,
          "title": ""
        },
        "id": "k3V06n3OHWMH"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import IntegerType, StringType, StructField, StructType\n",
        "\n",
        "# Insert a new record into the Delta table\n",
        "new_data = [(106, 'C006', 'Keyboard', 2, 50)]\n",
        "columns = [\"OrderID\", \"CustomerID\", \"Product\", \"Quantity\", \"Price\"]\n",
        "\n",
        "# Define the schema of the Delta table\n",
        "schema = StructType([\n",
        "    StructField(\"OrderID\", IntegerType(), nullable=False),\n",
        "    StructField(\"CustomerID\", StringType(), nullable=False),\n",
        "    StructField(\"Product\", StringType(), nullable=False),\n",
        "    StructField(\"Quantity\", IntegerType(), nullable=False),\n",
        "    StructField(\"Price\", IntegerType(), nullable=False)\n",
        "])\n",
        "\n",
        "# Create a DataFrame with new data and specified schema\n",
        "new_df = spark.createDataFrame(new_data, schema)\n",
        "\n",
        "# Append the new data to the Delta table\n",
        "new_df.write.format(\"delta\").mode(\"append\").save(\"/delta/orders\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "implicitDf": true,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3296f61b-5d9f-44e8-8359-420f5ed081dd",
          "showTitle": false,
          "title": ""
        },
        "id": "Dhw4m9_QHWML",
        "outputId": "7ef2631f-fb7c-4a1b-b78e-b73c94f40bf5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody><tr><td>1</td><td>1</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  1,
                  1
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "createTempViewForImplicitDf": true,
                "dataframeName": "_sqldf",
                "executionCount": 86
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "num_affected_rows",
                  "type": "\"long\""
                },
                {
                  "metadata": "{}",
                  "name": "num_inserted_rows",
                  "type": "\"long\""
                }
              ],
              "type": "table"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%sql\n",
        "-- Insert a new record using SQL\n",
        "INSERT INTO delta.`/delta/orders`\n",
        "VALUES (107, '2024-01-06', 'C006', 'Keyboard', 2, 50);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "d2bba3d9-7537-4b75-b068-a89fa2d1fba8",
          "showTitle": false,
          "title": ""
        },
        "id": "QwT3-tdRHWMQ"
      },
      "source": [
        "Task 4: Merge Data (Slowly Changing Dimension - SCD Type 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8969e647-9534-43b8-8931-7f3c232e7e14",
          "showTitle": false,
          "title": ""
        },
        "id": "vELB-f9jHWMS"
      },
      "outputs": [],
      "source": [
        "# New data representing updated orders\n",
        "new_data = [(101, '2024-01-10', 'C001', 'Laptop', 2, 1200),  # Updated order for Laptop\n",
        "            (106, '2024-01-12', 'C006', 'Keyboard', 3, 50)]   # New order for Keyboard\n",
        "\n",
        "columns = [\"OrderID\", \"OrderDate\", \"CustomerID\", \"Product\", \"Quantity\", \"Price\"]\n",
        "\n",
        "# Create a DataFrame with the new data\n",
        "new_df = spark.createDataFrame(new_data, columns)\n",
        "\n",
        "# Merge the new data into the Delta table (SCD Type 2)\n",
        "delta_table.alias(\"old\").merge(\n",
        "    new_df.alias(\"new\"),\n",
        "    \"old.OrderID = new.OrderID\"\n",
        ").whenMatchedUpdate(set={\n",
        "    \"OrderDate\": \"new.OrderDate\",\n",
        "    \"CustomerID\": \"new.CustomerID\",\n",
        "    \"Product\": \"new.Product\",\n",
        "    \"Quantity\": \"new.Quantity\",\n",
        "    \"Price\": \"new.Price\"\n",
        "}).whenNotMatchedInsertAll().execute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "a8464445-ce7b-4e9c-9bcf-ac771df62f25",
          "showTitle": false,
          "title": ""
        },
        "id": "iH0zlELqHWMT"
      },
      "source": [
        "Task 5: Explore Delta Table Internals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "83ebe5ca-b247-4850-9659-f96d14e249bb",
          "showTitle": false,
          "title": ""
        },
        "id": "sH-OkrOXHWMW",
        "outputId": "0e2af924-adb2-4a6d-a996-28acde15082f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------------------+----------------+--------------------+---------+--------------------+----+-----------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
            "|version|          timestamp|          userId|            userName|operation| operationParameters| job|         notebook|           clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
            "+-------+-------------------+----------------+--------------------+---------+--------------------+----+-----------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
            "|     35|2024-09-17 05:04:39|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|         34|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     34|2024-09-17 05:04:37|2929584751483774|azuser2141_mml.lo...|    MERGE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         33|WriteSerializable|        false|{numTargetRowsCop...|        NULL|Databricks-Runtim...|\n",
            "|     33|2024-09-17 04:58:42|2929584751483774|azuser2141_mml.lo...|    WRITE|{mode -> Append, ...|NULL|{418182220691607}|0912-053226-p5usobai|         32|WriteSerializable|         true|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
            "|     32|2024-09-17 04:57:46|2929584751483774|azuser2141_mml.lo...|    WRITE|{mode -> Append, ...|NULL|{418182220691607}|0912-053226-p5usobai|         31|WriteSerializable|         true|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
            "|     31|2024-09-17 04:56:02|2929584751483774|azuser2141_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         30|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     30|2024-09-17 04:55:27|2929584751483774|azuser2141_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         29|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     29|2024-09-17 04:55:01|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|         28|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     28|2024-09-17 04:54:58|2929584751483774|azuser2141_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         27|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     27|2024-09-17 04:54:36|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|         26|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     26|2024-09-17 04:54:34|2929584751483774|azuser2141_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         25|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     25|2024-09-17 04:53:11|2929584751483774|azuser2141_mml.lo...|    WRITE|{mode -> Overwrit...|NULL|{418182220691607}|0912-053226-p5usobai|         24|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
            "|     24|2024-09-17 04:51:47|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|         23|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     23|2024-09-17 04:51:46|2929584751483774|azuser2141_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         22|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     22|2024-09-17 04:51:44|2929584751483774|azuser2141_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         21|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     21|2024-09-17 04:50:56|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|         20|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     20|2024-09-17 04:50:54|2929584751483774|azuser2141_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         19|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     19|2024-09-17 04:50:53|2929584751483774|azuser2141_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         18|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     18|2024-09-17 04:50:07|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|         17|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     17|2024-09-17 04:50:05|2929584751483774|azuser2141_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         16|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "|     16|2024-09-17 04:50:04|2929584751483774|azuser2141_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         15|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
            "+-------+-------------------+----------------+--------------------+---------+--------------------+----+-----------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+--------------------+----+-----------+------------------+--------------------+-------------------+----------------+-----------------+--------+-----------+--------------------+----------------+----------------+-----------------+--------------------+\n",
            "|format|                  id|name|description|          location|           createdAt|       lastModified|partitionColumns|clusteringColumns|numFiles|sizeInBytes|          properties|minReaderVersion|minWriterVersion|    tableFeatures|          statistics|\n",
            "+------+--------------------+----+-----------+------------------+--------------------+-------------------+----------------+-----------------+--------+-----------+--------------------+----------------+----------------+-----------------+--------------------+\n",
            "| delta|505a9da5-3e4f-469...|NULL|       NULL|dbfs:/delta/orders|2024-09-17 04:41:...|2024-09-17 05:04:39|              []|               []|       1|       1594|{delta.enableDele...|               3|               7|[deletionVectors]|{numRowsDeletedBy...|\n",
            "+------+--------------------+----+-----------+------------------+--------------------+-------------------+----------------+-----------------+--------+-----------+--------------------+----------------+----------------+-----------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check the transaction history using PySpark\n",
        "delta_table.history().show()\n",
        "# Check file details using PySpark\n",
        "spark.sql(\"DESCRIBE DETAIL delta.`/delta/orders`\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "implicitDf": true,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "56e83bc9-65ef-4189-be31-0f44351e86fa",
          "showTitle": false,
          "title": ""
        },
        "id": "y0Lq-OT_HWMa",
        "outputId": "1ad27fe4-6ce2-4b04-ea31-dafc0122b66b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>format</th><th>id</th><th>name</th><th>description</th><th>location</th><th>createdAt</th><th>lastModified</th><th>partitionColumns</th><th>clusteringColumns</th><th>numFiles</th><th>sizeInBytes</th><th>properties</th><th>minReaderVersion</th><th>minWriterVersion</th><th>tableFeatures</th><th>statistics</th></tr></thead><tbody><tr><td>delta</td><td>505a9da5-3e4f-469c-ba9c-1974afaed544</td><td>null</td><td>null</td><td>dbfs:/delta/orders</td><td>2024-09-17T04:41:18.952Z</td><td>2024-09-17T05:04:39Z</td><td>List()</td><td>List()</td><td>1</td><td>1594</td><td>Map(delta.enableDeletionVectors -> true)</td><td>3</td><td>7</td><td>List(deletionVectors)</td><td>Map(numRowsDeletedByDeletionVectors -> 0, numDeletionVectors -> 0)</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  "delta",
                  "505a9da5-3e4f-469c-ba9c-1974afaed544",
                  null,
                  null,
                  "dbfs:/delta/orders",
                  "2024-09-17T04:41:18.952Z",
                  "2024-09-17T05:04:39Z",
                  [],
                  [],
                  1,
                  1594,
                  {
                    "delta.enableDeletionVectors": "true"
                  },
                  3,
                  7,
                  [
                    "deletionVectors"
                  ],
                  {
                    "numDeletionVectors": 0,
                    "numRowsDeletedByDeletionVectors": 0
                  }
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "createTempViewForImplicitDf": true,
                "dataframeName": "_sqldf",
                "executionCount": 97
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "format",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "id",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "name",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "description",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "location",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "createdAt",
                  "type": "\"timestamp\""
                },
                {
                  "metadata": "{}",
                  "name": "lastModified",
                  "type": "\"timestamp\""
                },
                {
                  "metadata": "{}",
                  "name": "partitionColumns",
                  "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
                },
                {
                  "metadata": "{}",
                  "name": "clusteringColumns",
                  "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
                },
                {
                  "metadata": "{}",
                  "name": "numFiles",
                  "type": "\"long\""
                },
                {
                  "metadata": "{}",
                  "name": "sizeInBytes",
                  "type": "\"long\""
                },
                {
                  "metadata": "{}",
                  "name": "properties",
                  "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
                },
                {
                  "metadata": "{}",
                  "name": "minReaderVersion",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "minWriterVersion",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "tableFeatures",
                  "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
                },
                {
                  "metadata": "{}",
                  "name": "statistics",
                  "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"long\",\"valueContainsNull\":true}"
                }
              ],
              "type": "table"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%sql\n",
        "-- Check the transaction history using SQL\n",
        "DESCRIBE HISTORY delta.`/delta/orders`;\n",
        "-- Check file details using SQL\n",
        "DESCRIBE DETAIL delta.`/delta/orders`;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "b01e97d9-8511-47c1-8a32-d7d7e313b425",
          "showTitle": false,
          "title": ""
        },
        "id": "hTcQX77kHWMh"
      },
      "source": [
        "Task 6: Time Travel in Delta Tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "85218661-8610-42ea-a9ec-2529c7d433ad",
          "showTitle": false,
          "title": ""
        },
        "id": "kgygzJMIHWMj",
        "outputId": "caaad677-cc17-436f-b10e-a65764ed0809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+----------+-------+--------+-----+\n",
            "|OrderID| OrderDate|CustomerID|Product|Quantity|Price|\n",
            "+-------+----------+----------+-------+--------+-----+\n",
            "|    102|2024-01-02|      C002|  Phone|       1|  500|\n",
            "|    103|2024-01-03|      C003| Tablet|       3|  300|\n",
            "|    104|2024-01-04|      C004|Monitor|       1|  150|\n",
            "|    105|2024-01-05|      C005|  Mouse|       5|   20|\n",
            "|    101|2024-01-01|      C001| Laptop|       2| 1100|\n",
            "+-------+----------+----------+-------+--------+-----+\n",
            "\n",
            "+-------+----------+----------+-------+--------+-----+\n",
            "|OrderID| OrderDate|CustomerID|Product|Quantity|Price|\n",
            "+-------+----------+----------+-------+--------+-----+\n",
            "|    101|2024-01-01|      C001| Laptop|       2| 1000|\n",
            "|    102|2024-01-02|      C002|  Phone|       1|  500|\n",
            "|    103|2024-01-03|      C003| Tablet|       3|  300|\n",
            "|    104|2024-01-04|      C004|Monitor|       1|  150|\n",
            "|    105|2024-01-05|      C005|  Mouse|       5|   20|\n",
            "+-------+----------+----------+-------+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Query the table as it existed at a specific version\n",
        "df_version = spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(\"/delta/orders\")\n",
        "df_version.show()\n",
        "\n",
        "# Query the table as it existed at a specific timestamp\n",
        "df_timestamp = spark.read.format(\"delta\").option(\"timestampAsOf\", \"2024-09-17T04:41:20Z\").load(\"/delta/orders\")\n",
        "df_timestamp.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "851ba18f-34c9-4aa9-ab14-7cff15fd774a",
          "showTitle": false,
          "title": ""
        },
        "id": "FJCPUCMvHWMn"
      },
      "source": [
        "Task 7: Optimize Delta Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b2145723-064d-45e1-96f2-fcd780dc7f9e",
          "showTitle": false,
          "title": ""
        },
        "id": "yJ-XY-7fHWMr",
        "outputId": "e45a0fee-a474-46be-9dbb-ce2b18a0bbc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[path: string]"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Optimize the table and Z-order by Product column\n",
        "spark.sql(\"OPTIMIZE delta.`/delta/orders` ZORDER BY (Product)\")\n",
        "# Vacuum the Delta table to remove old versions of the files\n",
        "spark.sql(\"VACUUM delta.`/delta/orders` RETAIN 168 HOURS\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "7ac0b052-3a2e-4f87-9a2f-b6864b044e2f",
          "showTitle": false,
          "title": ""
        },
        "id": "kDwDBnU1HWMu"
      },
      "source": [
        "Task 8: Converting Parquet Files to Delta Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3d8a0d1d-0d24-4e2f-b34f-47c924245fec",
          "showTitle": false,
          "title": ""
        },
        "id": "AVgZDD8XHWMx",
        "outputId": "7e2b41b6-fa0d-41b1-85af-05803b3f9d72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---------+----------+-------+--------+-----+\n",
            "|OrderID|OrderDate|CustomerID|Product|Quantity|Price|\n",
            "+-------+---------+----------+-------+--------+-----+\n",
            "+-------+---------+----------+-------+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
        "\n",
        "# Define the schema of your Parquet file\n",
        "schema = StructType([\n",
        "    StructField(\"OrderID\", StringType(), True),\n",
        "    StructField(\"OrderDate\", DateType(), True),\n",
        "    StructField(\"CustomerID\", StringType(), True),\n",
        "    StructField(\"Product\", StringType(), True),\n",
        "    StructField(\"Quantity\", IntegerType(), True),\n",
        "    StructField(\"Price\", DoubleType(), True),\n",
        "])\n",
        "\n",
        "parquet_path = \"/dbfs/FileStore/\"\n",
        "delta_path = \"/dbfs/FileStore/delta_table\"\n",
        "\n",
        "# Read Parquet data with the defined schema\n",
        "df_parquet = spark.read.format(\"parquet\").schema(schema).load(parquet_path)\n",
        "\n",
        "# Write the data in Delta format\n",
        "df_parquet.write.format(\"delta\").mode(\"overwrite\").save(delta_path)\n",
        "\n",
        "# Register the Delta table\n",
        "spark.sql(f\"CREATE TABLE delta_table USING DELTA LOCATION '{delta_path}'\")\n",
        "\n",
        "# Query the newly converted Delta table\n",
        "df_converted = spark.sql(\"SELECT * FROM delta_table\")\n",
        "df_converted.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "6f15b9df-a24d-479d-a771-c3efe81a7dc7",
          "showTitle": false,
          "title": ""
        },
        "id": "uwRrq6LTHWM1"
      },
      "source": [
        "### Creating and Scheduling a Job on Databricks using Notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "515ce7ab-44b9-49b5-bed6-fdc0749ba489",
          "showTitle": false,
          "title": ""
        },
        "id": "aNRqsXkmHWM3",
        "outputId": "339fe920-3f84-41cb-c4f2-338c01ffb2e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+----------+-------+--------+------+-----------+\n",
            "|OrderID| OrderDate|CustomerID|Product|Quantity| Price|TotalAmount|\n",
            "+-------+----------+----------+-------+--------+------+-----------+\n",
            "|    101|2024-01-01|      C001| Laptop|       2|1000.0|     2000.0|\n",
            "|    103|2024-01-03|      C003| Tablet|       3| 300.0|      900.0|\n",
            "|    105|2024-01-05|      C005|  Mouse|       5|  20.0|      100.0|\n",
            "+-------+----------+----------+-------+--------+------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, DateType, IntegerType, DoubleType\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Define the schema\n",
        "schema = StructType([\n",
        "    StructField(\"OrderID\", StringType(), True),\n",
        "    StructField(\"OrderDate\", DateType(), True),\n",
        "    StructField(\"CustomerID\", StringType(), True),\n",
        "    StructField(\"Product\", StringType(), True),\n",
        "    StructField(\"Quantity\", IntegerType(), True),\n",
        "    StructField(\"Price\", DoubleType(), True),\n",
        "])\n",
        "\n",
        "# Read CSV file into a DataFrame\n",
        "csv_path = \"dbfs:/FileStore/streaming/input/orders.csv\"\n",
        "df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(schema).load(csv_path)\n",
        "\n",
        "# Add TotalAmount column and filter rows\n",
        "df_transformed = df.withColumn(\"TotalAmount\", col(\"Quantity\") * col(\"Price\")) \\\n",
        "                    .filter(col(\"Quantity\") > 1)\n",
        "\n",
        "# Write the transformed data to a Delta table with schema evolution enabled\n",
        "delta_path = \"/dbfs/FileStore/delta_table\"\n",
        "df_transformed.write.format(\"delta\").option(\"mergeSchema\", \"true\").mode(\"overwrite\").save(delta_path)\n",
        "\n",
        "# Register the Delta table\n",
        "spark.sql(f\"CREATE TABLE IF NOT EXISTS delta_table USING DELTA LOCATION '{delta_path}'\")\n",
        "\n",
        "# Query the Delta table to verify the transformation\n",
        "df_converted = spark.sql(\"SELECT * FROM delta_table\")\n",
        "df_converted.show()"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "environmentMetadata": null,
      "language": "python",
      "notebookMetadata": {
        "mostRecentlyExecutedCommandWithImplicitDF": {
          "commandId": 418182220691854,
          "dataframes": [
            "_sqldf"
          ]
        },
        "pythonIndentUnit": 4
      },
      "notebookName": "Sep 17",
      "widgets": {}
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}