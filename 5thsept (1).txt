!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Initialize Spark Session
spark = SparkSession.builder \
    .appName("Employee Salary Data Transformation") \
    .getOrCreate()

import pandas as pd

# Create a sample CSV data
data = {
    "name": ["John", "Jane", "Mike", "Emily", "Alex"],
    "age": [28, 32, 45, 23, 36],
    "gender": ["Male", "Female", "Male", "Female", "Male"],
    "salary": [60000, 72000, 84000, 52000, 67000]
}

df = pd.DataFrame(data)

# Save the DataFrame as a CSV file
csv_file_path = "/content/sample_people.csv"
df.to_csv(csv_file_path, index=False)

# Confirm the CSV file is created
print(f"CSV file created at: {csv_file_path}")


# Load CSV data
employee_df = spark.read.csv("/content/sample_people.csv", header=True, inferSchema=True)

# Check data schema
employee_df.printSchema()
employee_df.show(5)

# Filter employees aged 30 and above
filtered_employee_df = employee_df.filter(col("age") >= 30)

# Show filtered data
filtered_employee_df.show(5)

# Add new column 'salary_with_bonus'
employee_with_bonus_df = filtered_employee_df.withColumn(
    "salary_with_bonus", col("salary") * 1.10
)

# Show data with the new column
employee_with_bonus_df.show(5)

# Group by gender and calculate average salary
salary_by_gender_df = employee_with_bonus_df.groupBy("gender") \
    .agg({"salary": "avg"}) \
    .withColumnRenamed("avg(salary)", "average_salary")

# Show average salary by gender
salary_by_gender_df.show()

# Save the transformed data to a Parquet file
employee_with_bonus_df.write.mode("overwrite").parquet("/path_to_output_directory/employee_transformed_data.parquet")


# Read back the Parquet file to verify
loaded_df = spark.read.parquet("/path_to_output_directory/employee_transformed_data.parquet")

# Show the loaded data
loaded_df.show(5)